{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "553d4969-bcbb-4afa-829e-0811dcd827a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cde6dd8a-7825-49dd-b56f-5e64b874c4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixlons(nci,latdim,latstr,londim,lonstr):\n",
    "# This function makes lat/lon coordinate names\n",
    "# and convention consistent between models\n",
    "    lonarray = np.zeros(nci[lonstr].shape)\n",
    "    ndim = lonarray.ndim\n",
    "    if ndim == 2:\n",
    "        if float(nci[lonstr].min()) < -1.:\n",
    "            for i in range(nci[lonstr].shape[0]):\n",
    "                for j in range(nci[lonstr].shape[1]):\n",
    "                    if float(nci[lonstr][i,j]) < 0.:\n",
    "                        lonarray[i,j] = nci[lonstr][i,j].data + 360.\n",
    "                    else:\n",
    "                        lonarray[i,j] = nci[lonstr][i,j].data\n",
    "            nci[lonstr] = ([latdim, londim], lonarray)\n",
    "    elif ndim == 1:\n",
    "        if float(nci[lonstr].min()) < -1.:\n",
    "            for i in range(nci[lonstr].shape[0]):\n",
    "                if float(nci[lonstr][i]) < 0.:\n",
    "                    lonarray[i] = nci[lonstr][i].data + 360.\n",
    "                else:\n",
    "                    lonarray[i] = nci[lonstr][i].data\n",
    "            nci[lonstr] = ([londim], lonarray)\n",
    "    nci = nci.rename({lonstr:'lon',latstr:'lat'})\n",
    "    return nci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77cdec70-e571-4b1c-a700-147cd7f4ca47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_ens(nci,variable,fili,variants,model,exp):\n",
    "# This function reads all ensemble members stored for a given model\n",
    "# and concatenates them into a single dataset for one variable at a time\n",
    "    # Variables:\n",
    "        # nci: dictionary into which the datasets are stored\n",
    "        # variable: name of variable in CMIP6 file\n",
    "        # fili: sorted list of CMIP6 files to be read from\n",
    "        # variants: list of ensemble variant names to be read\n",
    "        # model: name of CMIP6 model\n",
    "        # exp: name of CMIP6 experiment\n",
    "    print('|=====| Beginning to read data for ' + variable)\n",
    "    print('|=====| (nens = ' + str(len(variants)) + ')')\n",
    "    nfil = len(fili)\n",
    "    if exp == 'historical':\n",
    "        timslic = slice('1900-01-01','2014-12-30')\n",
    "    elif exp in ['ssp245','ssp370','ssp585']:\n",
    "        timslic = slice('2015-01-01','2100-12-30')\n",
    "    else:\n",
    "        print('Invalid experiment name')\n",
    "        return\n",
    "    ie = 0\n",
    "    cc = 0\n",
    "    oddlatlon = False\n",
    "    for ifil in range(nfil):\n",
    "        chckvar = variants[ie]\n",
    "        vari = fili[ifil].split('/')[-3]\n",
    "        if chckvar == vari:\n",
    "            if cc == 0:\n",
    "                print('|=====|=====| Beginning to read in ensemble member: ' + variants[ie])\n",
    "                tmp = xr.open_dataset(fili[ifil],engine='netcdf4',drop_variables=['lat_bnds','lon_bnds','time_bnds','plev_bnds'])\n",
    "                if model == 'EC-Earth3':\n",
    "                    tmp=tmp.load()\n",
    "                latstr,lonstr,latdim,londim = coordnames(tmp)\n",
    "                if latstr != 'lat' or lonstr != 'lon':\n",
    "                    tmp = tmp.rename({lonstr: 'lon',latstr: 'lat'})\n",
    "                    oglonstr = lonstr\n",
    "                    oglatstr = latstr\n",
    "                    lonstr = 'lon'\n",
    "                    latstr = 'lat'\n",
    "                    oddlatlon = True\n",
    "                tmp = fixlons(tmp,latdim,latstr,londim,lonstr)\n",
    "                if variable == 'zg':\n",
    "                    tmp = tmp.sel(plev=[50000.,20000.,],method='nearest')\n",
    "                    tmp = tmp.assign_coords(plev = [50000.,20000.])\n",
    "                cc += 1\n",
    "            else:\n",
    "                tmp2 = xr.open_dataset(fili[ifil], engine='netcdf4',drop_variables=['lat_bnds','lon_bnds','time_bnds','plev_bnds'])\n",
    "                if oddlatlon:\n",
    "                    tmp2 = tmp2.rename({oglonstr: 'lon',oglatstr: 'lat'})\n",
    "                tmp2 = fixlons(tmp2,latdim,latstr,londim,lonstr)\n",
    "                if variable == 'zg':\n",
    "                    tmp2 = tmp2.sel(plev=[50000.,20000.,],method='nearest')\n",
    "                    tmp2 = tmp2.assign_coords(plev = [50000.,20000.])\n",
    "                if tmp['lat'][0] != tmp2['lat'][0]:\n",
    "                    tmp2['lat'] = tmp['lat']\n",
    "                tmp = xr.concat( [tmp, tmp2], dim='time')\n",
    "            if ifil != nfil-1:\n",
    "                if chckvar != fili[ifil+1].split('/')[-3] and ie == 0:\n",
    "                    tmp = tmp.sel(time=timslic)\n",
    "                    nci[variable] = tmp\n",
    "                    nci[variable] = nci[variable].expand_dims(dim=dict(ens=[variants[ie]]))\n",
    "                    ie += 1\n",
    "                    cc = 0\n",
    "                elif chckvar != fili[ifil+1].split('/')[-3]:\n",
    "                    tmp = tmp.sel(time=timslic)\n",
    "                    if tmp['lat'][0] != nci[variable]['lat'][0]:\n",
    "                        tmp['lat'] = nci[variable]['lat']\n",
    "                    tmp = tmp.expand_dims(dim=dict(ens=[variants[ie]]))\n",
    "                    nci[variable] = xr.concat( [nci[variable], tmp], dim='ens')\n",
    "                    ie += 1\n",
    "                    cc = 0\n",
    "            elif ifil == nfil-1 and ie == 0:\n",
    "                tmp = tmp.sel(time=timslic)\n",
    "                tmp = tmp.expand_dims(dim=dict(ens=[variants[ie]]))\n",
    "                nci[variable] = tmp\n",
    "            else:\n",
    "                tmp = tmp.sel(time=timslic)\n",
    "                if tmp['lat'][0] != nci[variable]['lat'][0]:\n",
    "                    tmp['lat'] = nci[variable]['lat']\n",
    "                tmp = tmp.expand_dims(dim=dict(ens=[variants[ie]]))\n",
    "                nci[variable] = xr.concat( [nci[variable], tmp], dim='ens')\n",
    "    return nci[variable]\n",
    "    print('|=====| Successfully read in data for ' + variable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef29091c-8b07-4cd5-8839-225334b4a3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordnames(nci):\n",
    "# This function determines what coordinate variable names\n",
    "# are used by the input dataset\n",
    "    if 'latitude' in list(nci.variables):\n",
    "        latstr = 'latitude'\n",
    "    elif 'lat' in list(nci.variables):\n",
    "        latstr = 'lat'\n",
    "    elif 'nav_lat' in list(nci.variables):\n",
    "        latstr = 'nav_lat'\n",
    "\n",
    "    if 'longitude' in list(nci.variables):\n",
    "        lonstr = 'longitude'\n",
    "    elif 'lon' in list(nci.variables):\n",
    "        lonstr = 'lon'\n",
    "    elif 'nav_lon' in list(nci.variables):\n",
    "        lonstr = 'nav_lon'\n",
    "\n",
    "    if 'lat' in list(nci.dims):\n",
    "        latdim = 'lat'    \n",
    "        londim = 'lon'\n",
    "    elif 'latitude' in list(nci.dims):\n",
    "        latdim = 'latitude'\n",
    "        londim = 'longitude'\n",
    "    elif 'nav_lat' in list(nci.dims):\n",
    "        latdim = 'nav_lat'\n",
    "        londim = 'nav_lon'\n",
    "    elif 'x' in list(nci.dims):\n",
    "        latdim = 'y'\n",
    "        londim = 'x'\n",
    "    else:\n",
    "        latdim = 'j'\n",
    "        londim = 'i'\n",
    "    return latstr,lonstr,latdim,londim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568192f0-f9b7-4673-b44e-e7fdf4bdef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_cmip6(model,experiment):\n",
    "# This function stores pr and tas CMIP6 data for a given model and experiment\n",
    "# into a single netCDF file with consistent coordinate variable names\n",
    "# Also computes ELI and Nino3.4 index\n",
    "\n",
    "    if model == 'ICON-ESM-LR':\n",
    "        print('|=====|=====|=====|=====|=====|=====|=====|=====|=====|=====|=====|')\n",
    "        print(model + ' has a weird grid.  Sort it out later')\n",
    "        return\n",
    "    elif model == 'MIROC-ES2H':\n",
    "        print('|=====|=====|=====|=====|=====|=====|=====|=====|=====|=====|=====|')\n",
    "        print(model + ' data only includes 1850.  Skipping.')\n",
    "        return\n",
    "    print('|=====|=====|=====|=====|=====|=====|=====|=====|=====|=====|=====|')\n",
    "    print('Beginning preprocessing of CMIP6 data for model: ' + model + ' ' + exp)\n",
    "\n",
    "    diri = '/glade/scratch/nlybarger/data/climate_data/cmip6/'+ experiment + '/Amon/'\n",
    "    nci = {}\n",
    "    filo = '/glade/scratch/nlybarger/data/climate_data/cmip6/postproc/' + model + '.' + experiment + '.nc'\n",
    "\n",
    "    if os.path.exists(filo):\n",
    "        print('Computation already completed for model: ' + model + ' ' + experiment)\n",
    "        return\n",
    "    \n",
    "    if experiment == 'historical' and model == 'EC-Earth3':\n",
    "        variants = ['r10i1p1f1','r11i1p1f1','r12i1p1f1','r13i1p1f1','r14i1p1f1','r15i1p1f1',\n",
    "                    'r16i1p1f1','r17i1p1f1','r18i1p1f1','r19i1p1f1','r1i1p1f1',\n",
    "                    'r21i1p1f1','r22i1p1f1','r23i1p1f1','r24i1p1f1','r25i1p1f1','r2i1p1f1',\n",
    "                    'r3i1p1f1','r4i1p1f1','r6i1p1f1','r7i1p1f1','r9i1p1f1']\n",
    "    if experiment == 'ssp245' and model == 'EC-Earth3':\n",
    "        variants = ['r101i1p1f1','r102i1p1f1','r103i1p1f1','r104i1p1f1','r105i1p1f1',\n",
    "                    'r106i1p1f1','r107i1p1f1','r108i1p1f1','r109i1p1f1','r10i1p1f1',\n",
    "                    'r10i1p1f2','r110i1p1f1','r111i1p1f1','r112i1p1f1','r113i1p1f1',\n",
    "                    'r114i1p1f1','r115i1p1f1','r116i1p1f1','r117i1p1f1','r118i1p1f1',\n",
    "                    'r119i1p1f1','r11i1p1f1','r120i1p1f1','r121i1p1f1','r122i1p1f1',\n",
    "                    'r123i1p1f1','r124i1p1f1','r125i1p1f1','r126i1p1f1','r127i1p1f1',\n",
    "                    'r128i1p1f1','r129i1p1f1','r130i1p1f1','r131i1p1f1',\n",
    "                    'r132i1p1f1','r133i1p1f1','r134i1p1f1','r135i1p1f1','r136i1p1f1',\n",
    "                    'r137i1p1f1','r138i1p1f1','r139i1p1f1','r13i1p1f1','r13i1p1f2',\n",
    "                    'r140i1p1f1','r141i1p1f1','r142i1p1f1','r143i1p1f1','r144i1p1f1',\n",
    "                    'r145i1p1f1','r146i1p1f1','r147i1p1f1','r148i1p1f1','r149i1p1f1',\n",
    "                    'r150i1p1f1','r15i1p1f1','r16i1p1f2','r18i1p1f2','r1i1p1f1','r20i1p1f2',\n",
    "                    'r22i1p1f2','r24i1p1f2','r26i1p1f2','r28i1p1f2',\n",
    "                    'r2i1p1f2','r4i1p1f1','r6i1p1f1','r6i1p1f2','r7i1p1f2']\n",
    "    if experiment == 'ssp370' and model == 'EC-Earth3':\n",
    "        variants = ['r101i1p1f1','r102i1p1f1','r103i1p1f1','r104i1p1f1','r105i1p1f1','r106i1p1f1',\n",
    "                    'r107i1p1f1','r108i1p1f1','r109i1p1f1','r110i1p1f1','r111i1p1f1','r112i1p1f1','r113i1p1f1',\n",
    "                    'r114i1p1f1','r115i1p1f1','r116i1p1f1','r117i1p1f1','r118i1p1f1','r119i1p1f1','r11i1p1f1',\n",
    "                    'r120i1p1f1','r121i1p1f1','r122i1p1f1','r123i1p1f1','r124i1p1f1','r125i1p1f1','r126i1p1f1',\n",
    "                    'r127i1p1f1','r128i1p1f1','r129i1p1f1','r130i1p1f1','r131i1p1f1','r132i1p1f1','r133i1p1f1',\n",
    "                    'r134i1p1f1','r135i1p1f1','r136i1p1f1','r137i1p1f1','r138i1p1f1','r139i1p1f1','r13i1p1f1',\n",
    "                    'r140i1p1f1','r141i1p1f1','r142i1p1f1','r143i1p1f1','r144i1p1f1','r145i1p1f1','r146i1p1f1',\n",
    "                    'r147i1p1f1','r148i1p1f1','r149i1p1f1','r150i1p1f1','r15i1p1f1','r1i1p1f1','r4i1p1f1','r6i1p1f1','r9i1p1f1']\n",
    "    if experiment == 'historical' and model == 'EC-Earth3-Veg':\n",
    "        variants = ['r10i1p1f1','r12i1p1f1','r14i1p1f1','r1i1p1f1','r2i1p1f1','r3i1p1f1','r4i1p1f1','r6i1p1f1']\n",
    "    if experiment == 'ssp245' and model == 'EC-Earth3-Veg':\n",
    "        variants = ['r12i1p1f1','r14i1p1f1','r1i1p1f1','r2i1p1f1','r3i1p1f1','r4i1p1f1','r6i1p1f1']\n",
    "\n",
    "    if experiment == 'ssp585' and model in ['ACCESS-CM2','ACCESS-ESM1-5','IPSL-CM6A-LR','MIROC-ES2L','MRI-ESM2-0']:\n",
    "        filipr = sorted(glob.glob(diri + 'pr/' + model + '/*/*/*2015*'))\n",
    "    elif experiment in ['historical','ssp245'] and model in ['EC-Earth3','EC-Earth3-Veg']:\n",
    "        butt = 0\n",
    "        if butt == 0:\n",
    "            filipr = []\n",
    "            butt = 1\n",
    "        for var in variants:\n",
    "            filipr.extend(sorted(glob.glob(diri + 'pr/' + model + '/' + var + '/*/*.nc')))\n",
    "    else:\n",
    "        filipr = sorted(glob.glob(diri + 'pr/' + model + '/*/*/*.nc'))\n",
    "    \n",
    "    if not filipr:\n",
    "        print('pr does not exist for ' + model + ' ' + exp)\n",
    "        return\n",
    "    \n",
    "# Just need to skip this code chunk for these models/experiments \n",
    "# due to explicitly defining their ensemble members\n",
    "    if experiment in ['historical','ssp245','ssp370'] and model == 'EC-Earth3':\n",
    "        print('lol')\n",
    "    elif experiment in ['historical','ssp245'] and model == 'EC-Earth3-Veg':\n",
    "        print('lol')\n",
    "    else:\n",
    "        variants = ['0']\n",
    "        i=0\n",
    "        for ifil in range(len(filipr)):\n",
    "            variant = filipr[ifil].split('/')[-3]\n",
    "            if variant not in variants:\n",
    "                if i > 0:\n",
    "                    variants.append(variant)\n",
    "                    i += 1\n",
    "                else:\n",
    "                    variants[i] = variant\n",
    "                    i += 1\n",
    "    nvar = len(variants)\n",
    "\n",
    "    nci['pr'] = read_all_ens(nci,'pr',filipr,variants,model,experiment)\n",
    "# Some models had superfluous files floating around, \n",
    "# so took special exceptions to pick out the right time period\n",
    "    if experiment == 'ssp585' and model in ['ACCESS-CM2','ACCESS-ESM1-5','IPSL-CM6A-LR','MIROC-ES2L','MRI-ESM2-0']:\n",
    "        filitas = sorted(glob.glob(diri + 'tas/' + model + '/*/*/*2015*'))\n",
    "    elif experiment in ['historical','ssp245'] and model in ['EC-Earth3','EC-Earth3-Veg']:\n",
    "        butt = 0\n",
    "        if butt == 0:\n",
    "            filitas = []\n",
    "            butt = 1\n",
    "        for var in variants:\n",
    "            filitas.extend(sorted(glob.glob(diri + 'tas/' + model + '/' + var + '/*/*')))\n",
    "    else:\n",
    "        filitas = sorted(glob.glob(diri + 'tas/' + model + '/*/*/*'))\n",
    "\n",
    "    nci['tas'] = read_all_ens(nci,'tas',filitas,variants,model,experiment)\n",
    "\n",
    "    varlist = list(nci.keys())\n",
    "    latstr,lonstr,latdim,londim = coordnames(nci['pr'])\n",
    "    \n",
    "# Compute ELI and Nino3.4 from 2-m air temperature\n",
    "    # 2-m air temp has been shown to be a very good proxy for SST, and\n",
    "    # is always on the same grid as the atmospheric variables, so is \n",
    "    # easier to work with\n",
    "    ntim = len(nci['tas']['time'])\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\",category=RuntimeWarning)\n",
    "\n",
    "        troptas = nci['tas']['tas'].sel(lat=slice(-5.,5.),drop=True).mean(dim=[latdim,londim],skipna=True)\n",
    "        tmp  = nci['tas']['tas'].sel(lat=slice(-5.,5.),lon=slice(130.,275.),drop=True)\n",
    "        troptasval = np.zeros((nvar,ntim,tmp.shape[2],tmp.shape[3]))\n",
    "        for i in range(tmp.shape[2]):\n",
    "            for j in range(tmp.shape[3]):\n",
    "                troptasval[:,:,i,j] = troptas.data\n",
    "        sstanom = tmp - troptasval\n",
    "        print('|=====| Beginning computation of ELI')\n",
    "        eli_mon = np.zeros((nvar,ntim))\n",
    "        if sstanom[lonstr].ndim == 1:\n",
    "            londat = np.zeros((sstanom[latstr].shape[0],sstanom[lonstr].shape[0]))\n",
    "            for i in range(sstanom[latstr].shape[0]):\n",
    "                londat[i,:] = sstanom[lonstr]\n",
    "\n",
    "            lonny = xr.DataArray(\n",
    "                        data = londat,\n",
    "                        dims = [latdim, londim],\n",
    "                        coords = dict(\n",
    "                            londim = ([londim], sstanom[londim].data),\n",
    "                            latdim = ([latdim], sstanom[latdim].data)),)\n",
    "        else:\n",
    "            lonny = sstanom[lonstr]\n",
    "        for it in range(ntim):\n",
    "            for iens in range(nvar):\n",
    "                eli_mon[iens,it] = lonny.where(sstanom[iens,it,:,:] > 0., drop=True).mean(skipna=True)\n",
    "\n",
    "        n34_sst = nci['tas'].sel(lat=slice(-5,5),lon=slice(190,240),drop=True)\n",
    "\n",
    "        tmp = n34_sst.groupby('time.month') - n34_sst.groupby('time.month').mean(dim='time')\n",
    "        tmp = tmp.mean(dim=[latdim,londim],skipna=True)\n",
    "        n34 = tmp.rolling(time=5,center=True).mean(dim='time')\n",
    "        n34['tas'][:,0] = (tmp['tas'][:,0] + tmp['tas'][:,1] + tmp['tas'][:,2])/3\n",
    "        n34['tas'][:,1] = (tmp['tas'][:,0] + tmp['tas'][:,1] + tmp['tas'][:,2] + tmp['tas'][:,3])/4\n",
    "        n34['tas'][:,2] = (tmp['tas'][:,0] + tmp['tas'][:,1] + tmp['tas'][:,2] + tmp['tas'][:,3] + tmp['tas'][:,4])/5\n",
    "        n34['tas'][:,3] = (tmp['tas'][:,1] + tmp['tas'][:,2] + tmp['tas'][:,3] + tmp['tas'][:,4] + tmp['tas'][:,5])/5\n",
    "        n34['tas'][:,4] = (tmp['tas'][:,2] + tmp['tas'][:,3] + tmp['tas'][:,4] + tmp['tas'][:,5] + tmp['tas'][:,6])/5\n",
    "\n",
    "        n34['tas'][:,-1] = (tmp['tas'][:,-1] + tmp['tas'][:,-2] + tmp['tas'][:,-3])/3\n",
    "        n34['tas'][:,-2] = (tmp['tas'][:,-1] + tmp['tas'][:,-2] + tmp['tas'][:,-3] + tmp['tas'][:,-4])/4\n",
    "        n34['tas'][:,-3] = (tmp['tas'][:,-1] + tmp['tas'][:,-2] + tmp['tas'][:,-3] + tmp['tas'][:,-4] + tmp['tas'][:,-5])/5\n",
    "        n34['tas'][:,-4] = (tmp['tas'][:,-2] + tmp['tas'][:,-3] + tmp['tas'][:,-4] + tmp['tas'][:,-5] + tmp['tas'][:,-6])/5\n",
    "        n34['tas'][:,-5] = (tmp['tas'][:,-3] + tmp['tas'][:,-4] + tmp['tas'][:,-5] + tmp['tas'][:,-6] + tmp['tas'][:,-7])/5\n",
    "        print(n34)\n",
    "\n",
    "        enso_ind = xr.Dataset(\n",
    "        data_vars = dict(\n",
    "                    eli=(['ens','time'], eli_mon),\n",
    "                    n34=(['ens','time'], n34['tas'].data),\n",
    "                    ),\n",
    "                coords = dict(\n",
    "                    time = nci['tas']['time'].data,\n",
    "                    ens = variants,\n",
    "                    ),\n",
    "                attrs=dict(description='ELI and Nino 3.4 data from: '+model),\n",
    "                    )\n",
    "        print('|=====| Completed computation of ELI')\n",
    "\n",
    "    nci['pr']['pr'] = nci['pr']['pr']*86400\n",
    "\n",
    "    nco = nci['pr']['pr'].to_dataset()\n",
    "    nco = nco.assign(tas=nci['tas']['tas'])\n",
    "    nco = nco.assign(eli=enso_ind['eli'])\n",
    "    nco = nco.assign(n34=enso_ind['n34'])\n",
    "\n",
    "    nco.to_netcdf(filo,mode='w',format='NETCDF4')\n",
    "\n",
    "    del nco\n",
    "    del nci\n",
    "    del n34_sst\n",
    "    del n34\n",
    "    del troptas\n",
    "    del troptasval\n",
    "    del tmp\n",
    "    del sstanom\n",
    "    del enso_ind\n",
    "    \n",
    "    print('Completed preprocessing of CMIP6 data for model: ' + model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcfc46b-a4c3-4534-bc3b-044d1fe98357",
   "metadata": {},
   "outputs": [],
   "source": [
    "for exp in ['historical','ssp245','ssp370','ssp585']:\n",
    "    diri = '/glade/scratch/nlybarger/data/climate_data/cmip6/'+exp+'/Amon/'\n",
    "    filis = sorted(glob.glob(diri + 'tas/*'))\n",
    "    nfil = len(filis)\n",
    "\n",
    "    models = ['0']*nfil\n",
    "    for i in range(nfil):\n",
    "        models[i] = filis[i].split('/')[-1]\n",
    "    for mod in models:\n",
    "        prep_cmip6(mod,exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bf62c2-0a35-4dfd-9d2d-37a78ce93722",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mypy",
   "language": "python",
   "name": "mypy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
